{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initial value setting\n",
    "student_id = '2211224'\n",
    "b = list(map(int, student_id[3:7]))\n",
    "\n",
    "x = [\n",
    "    [1,1],\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "]\n",
    "y = [1, -1, 1, -1]\n",
    "learning_rate = 1.0\n",
    "\n",
    "def activation_function(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def loss_function(y, predicted):\n",
    "    return (1/2)*(y-predicted)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_11 = 0.4\n",
      "w_12 = -0.6\n",
      "w_13 = 0.4\n",
      "w_14 = 0.4\n",
      "w_15 = 0.4\n",
      "w_16 = -0.6\n",
      "w_21 = -0.4\n",
      "w_22 = -0.4\n",
      "w_23 = -0.6\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((3,7))\n",
    "\n",
    "def print_weight():\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,7):\n",
    "            if i == 2 and j >= 4: break\n",
    "            print('w_'+str(i)+str(j)+' =', w[i][j])\n",
    "\n",
    "\n",
    "w[1][1] = (b[2]+2)/10\n",
    "w[1][2] = -(b[3]+2)/10\n",
    "w[1][3] = (b[1]+2)/10\n",
    "w[1][4] = (b[1]+2)/10\n",
    "w[1][5] = (b[2]+2)/10\n",
    "w[1][6] = -(b[3]+2)/10\n",
    "w[2][1] = -(b[1]+2)/10\n",
    "w[2][2] = -(b[2]+2)/10\n",
    "w[2][3] = -(b[3]+2)/10\n",
    "\n",
    "print_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x:list, y:int):\n",
    "    # forward\n",
    "    u_1 = x[0]*w[1][1] + x[1]*w[1][3] + 1*w[1][5]\n",
    "    z_1 = activation_function(u_1)\n",
    "    u_2 = x[0]*w[1][2] + x[1]*w[1][4] + 1*w[1][6]\n",
    "    z_2 = activation_function(u_2)\n",
    "    u_3 = z_1*w[2][1] + z_2*w[2][2] + 1*w[2][3]\n",
    "    z_3 = activation_function(u_3)\n",
    "\n",
    "    # prediction\n",
    "    predicted = z_3\n",
    "\n",
    "    # calculate loss\n",
    "    loss = loss_function(y, predicted)\n",
    "\n",
    "    # calc gradients\n",
    "    grad = np.zeros((3,7))\n",
    "    grad[1][1] = -(y-predicted) * (1-z_3**2) * w[2][1] * (1-z_1**2) * x[0]\n",
    "    grad[1][2] = -(y-predicted) * (1-z_3**2) * w[2][2] * (1-z_2**2) * x[0]\n",
    "    grad[1][3] = -(y-predicted) * (1-z_3**2) * w[2][1] * (1-z_1**2) * x[1]\n",
    "    grad[1][4] = -(y-predicted) * (1-z_3**2) * w[2][2] * (1-z_2**2) * x[1]\n",
    "    grad[1][5] = -(y-predicted) * (1-z_3**2) * w[2][1] * (1-z_1**2) * 1\n",
    "    grad[1][6] = -(y-predicted) * (1-z_3**2) * w[2][2] * (1-z_2**2) * 1\n",
    "    grad[2][1] = -(y-predicted) * (1-z_3**2) * z_1\n",
    "    grad[2][2] = -(y-predicted) * (1-z_3**2) * z_2\n",
    "    grad[2][3] = -(y-predicted) * (1-z_3**2) * 1\n",
    "\n",
    "    # update weight\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,7):\n",
    "            if i == 2 and j >= 4: break\n",
    "            w[i][j] = w[i][j] - learning_rate * grad[i][j]\n",
    "    \n",
    "    print_weight()\n",
    "    print('predicted :', predicted)\n",
    "    print('true      :', y)\n",
    "    print('loss      :', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- No.1---\n",
      "w_11 = 0.2725884427261003\n",
      "w_12 = -0.8335259668495671\n",
      "w_13 = 0.2725884427261003\n",
      "w_14 = 0.1664740331504329\n",
      "w_15 = 0.2725884427261003\n",
      "w_16 = -0.8335259668495671\n",
      "w_21 = 0.470575970663195\n",
      "w_22 = -1.0934460038599134\n",
      "w_23 = 0.4442885618822009\n",
      "predicted : -0.5835619477026628\n",
      "true      : 1\n",
      "loss      : 1.2538342211059255\n",
      "--- No.2---\n",
      "w_11 = 0.2725884427261003\n",
      "w_12 = -0.8335259668495671\n",
      "w_13 = 0.10691477772522659\n",
      "w_14 = 0.503885943728844\n",
      "w_15 = 0.10691477772522659\n",
      "w_16 = -0.49611405627115607\n",
      "w_21 = 0.2382804691041646\n",
      "w_22 = -0.8208803934859523\n",
      "w_23 = -0.023204012209037228\n",
      "predicted : 0.8656945519550924\n",
      "true      : -1\n",
      "loss      : 1.7404080805974562\n",
      "--- No.3---\n",
      "w_11 = 0.2725884427261003\n",
      "w_12 = -0.8335259668495671\n",
      "w_13 = 0.10691477772522659\n",
      "w_14 = 0.503885943728844\n",
      "w_15 = 0.23756670013525144\n",
      "w_16 = -0.8554383755060249\n",
      "w_21 = 0.2973508284169426\n",
      "w_22 = -1.0754740174163993\n",
      "w_23 = 0.5313990320840448\n",
      "predicted : 0.36184287384343217\n",
      "true      : 1\n",
      "loss      : 0.2036222588322048\n",
      "--- No.4---\n",
      "w_11 = 0.21403245490995076\n",
      "w_12 = -0.7988325186957774\n",
      "w_13 = 0.10691477772522659\n",
      "w_14 = 0.503885943728844\n",
      "w_15 = 0.17901071231910193\n",
      "w_16 = -0.8207449273522351\n",
      "w_21 = 0.1785272896202714\n",
      "w_22 = -0.8393731900325399\n",
      "w_23 = 0.27861852653010094\n",
      "predicted : 0.9322990274542685\n",
      "true      : -1\n",
      "loss      : 1.8668897657503563\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "    print('--- No.'+str(t+1)+'---')\n",
    "    train(x[t], y[t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "688ad565c08edb0899b8bd0741344b16fcf0b3dbcc26d6e95bbc405bd5ad4682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
